{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pprint\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import tensorflow as tf\n",
    "from global_module.settings_module.set_dir import Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A visual check for the files in the dir\n",
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a weak heuristic to create the weak labels\n",
    "# These words came from the pre-processing to find the most common words in requests\n",
    "# We'll just call a sentence with such a word a \"request\"\n",
    "\n",
    "request_words = ('please','request','thanks', 'followup')\n",
    "\n",
    "def generate_weak_labels(sents):\n",
    "    wlabels = []\n",
    "    for sent in sents:\n",
    "        is_request = 'No'\n",
    "        words = sent.split()\n",
    "        for word in list(set(words)):\n",
    "            if word in request_words:\n",
    "                is_request = 'Yes'\n",
    "                break\n",
    "        wlabels.append(is_request)\n",
    "    return wlabels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data, strong and weak labels for the confidence/corrections network\n",
    "\n",
    "\n",
    "mode = 'TR'\n",
    "rel_dir = Directory(mode)\n",
    "# print(rel_dir.preprocessing_dir)\n",
    "print(rel_dir.data_path)\n",
    "\n",
    "# data directories for cnf and tar\n",
    "cnf_dir = rel_dir.data_path + '/cnf'\n",
    "\n",
    "# Create the cnf training, test and validation files\n",
    "\n",
    "raw_data_filename = cnf_dir + rel_dir.raw_data_filename\n",
    "data_filename = cnf_dir + rel_dir.data_filename\n",
    "gold_label_filename = cnf_dir + rel_dir.gold_label_filename\n",
    "weak_label_filename = cnf_dir + rel_dir.weak_label_filename\n",
    "\n",
    "data = pd.read_csv(raw_data_filename, sep='\\t')\n",
    "labels = data.iloc[:,0]\n",
    "sents = data.iloc[:,1]\n",
    "wlabels = generate_weak_labels(sents)\n",
    "\n",
    "# print(data)\n",
    "\n",
    "with open(data_filename, 'w') as fp:\n",
    "    for item in sents:\n",
    "        fp.write(item + '\\n')\n",
    "    \n",
    "with open(gold_label_filename, 'w') as fpg:\n",
    "    for item in labels:\n",
    "        fpg.write(item + '\\n')\n",
    "        \n",
    "with open(weak_label_filename, 'w') as fpw:\n",
    "    for item in wlabels:\n",
    "        fpw.write(item + '\\n')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the accuracy of our weakest annotator? \n",
    "# We'll count the number of sentences it gets right\n",
    "# Turns out that its just better than random\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for (y, y1) in zip(labels, wlabels):\n",
    "    # print(y, y1)\n",
    "    if y == y1:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "    \n",
    "accuracy = correct/total\n",
    "print(accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data, strong and weak labels\n",
    "\n",
    "\n",
    "mode = 'VA'\n",
    "rel_dir = Directory(mode)\n",
    "# print(rel_dir.preprocessing_dir)\n",
    "print(rel_dir.data_path)\n",
    "\n",
    "# data directories for cnf \n",
    "cnf_dir = rel_dir.data_path + '/cnf'\n",
    "\n",
    "\n",
    "# Create the cnf training, test and validation files\n",
    "\n",
    "raw_data_filename = cnf_dir + rel_dir.raw_data_filename\n",
    "data_filename = cnf_dir + rel_dir.data_filename\n",
    "gold_label_filename = cnf_dir + rel_dir.gold_label_filename\n",
    "weak_label_filename = cnf_dir + rel_dir.weak_label_filename\n",
    "\n",
    "data = pd.read_csv(raw_data_filename, sep='\\t')\n",
    "labels = data.iloc[:,0]\n",
    "sents = data.iloc[:,1]\n",
    "wlabels = generate_weak_labels(sents)\n",
    "\n",
    "# Split into test and validation\n",
    "xv, xt, yv, yt, yyv, yyt = train_test_split(\n",
    "        sents,\n",
    "        labels,\n",
    "        wlabels,\n",
    "        test_size=.5,\n",
    "        random_state=0,\n",
    "        stratify=labels)\n",
    "\n",
    "# print(data)\n",
    "\n",
    "with open(data_filename, 'w') as fp:\n",
    "    for item in xv:\n",
    "        fp.write(item + '\\n')\n",
    "    \n",
    "with open(gold_label_filename, 'w') as fpg:\n",
    "    for item in yv:\n",
    "        fpg.write(item + '\\n')\n",
    "        \n",
    "with open(weak_label_filename, 'w') as fpw:\n",
    "    for item in yyv:\n",
    "        fpw.write(item + '\\n')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the accuracy of our weakest annotator? \n",
    "# We'll count the number of sentences it gets right\n",
    "# Wow, that's a 70% accuracy with a very weak annotator\n",
    "\n",
    "correct = 0\n",
    "countgy = 0\n",
    "countwy = 0\n",
    "total = 0\n",
    "for (y, y1) in zip(labels, wlabels):\n",
    "    # print(y, y1)\n",
    "    if y == y1:\n",
    "        correct += 1\n",
    "    if y == \"Yes\":\n",
    "        countgy += 1\n",
    "    if y1 ==\"Yes\":\n",
    "        countwy += 1\n",
    "    total += 1\n",
    "    \n",
    "accuracy = correct/total\n",
    "print('accuracy: ', accuracy)\n",
    "print('correct in gold, correct in weak, ratio of correct in gold, ratio of correct in weak', countgy, countwy, \n",
    "     countgy/total, countwy/total)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data, labels and weak labels for the confidence network\n",
    "\n",
    "\n",
    "mode = 'TE'\n",
    "rel_dir = Directory(mode)\n",
    "# print(rel_dir.preprocessing_dir)\n",
    "print(rel_dir.data_path)\n",
    "\n",
    "# data directories for cnf \n",
    "cnf_dir = rel_dir.data_path + '/cnf'\n",
    "\n",
    "\n",
    "# Create the cnf training, test and validation files\n",
    "\n",
    "# Training\n",
    "\n",
    "# raw_data_filename = cnf_dir + rel_dir.raw_data_filename\n",
    "data_filename = cnf_dir + rel_dir.data_filename\n",
    "gold_label_filename = cnf_dir + rel_dir.gold_label_filename\n",
    "weak_label_filename = cnf_dir + rel_dir.weak_label_filename\n",
    "\n",
    "\n",
    "with open(data_filename, 'w') as fp:\n",
    "    for item in xt:\n",
    "        fp.write(item + '\\n')\n",
    "    \n",
    "with open(gold_label_filename, 'w') as fpg:\n",
    "    for item in yt:\n",
    "        fpg.write(item + '\\n')\n",
    "        \n",
    "with open(weak_label_filename, 'w') as fpw:\n",
    "    for item in yyt:\n",
    "        fpw.write(item + '\\n')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the accuracy of our weakest annotator? \n",
    "# We'll count the number of sentences it gets right\n",
    "# Wow, that's a 70% accuracy with a very weak annotator\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for (y, y1) in zip(labels, wlabels):\n",
    "    # print(y, y1)\n",
    "    if y == y1:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "    \n",
    "accuracy = correct/total\n",
    "print(accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlableled data\n",
    "# Walking the hierarcy of emails and getting all lines into a file\n",
    "# Varying levels of clean up also along the way\n",
    "# Fixed to remove whitespace and most header items in the emails\n",
    "\n",
    "root = '/Users/gkhanna/w266nlp/2018-summer-main/project/maildirAll'\n",
    "\n",
    "# Output file is a collection of lines from all the files/emails\n",
    "# in the hierarcy of email files\n",
    "line_count = 0\n",
    "f = open('/Users/gkhanna/w266nlp/2018-summer-main/project/outputFileLarge.txt', mode='w+')\n",
    "for dirname, dirnames, filenames in os.walk(root):\n",
    "    for filename in filenames:\n",
    "        # If a file starting with ., ignore it\n",
    "        if filename.startswith('.'):\n",
    "            continue\n",
    "        filepath = os.path.join(dirname, filename)\n",
    "        # Debug: print(filepath)\n",
    "        # I do not much care about non ascii stuff for this problem\n",
    "        of = open(filepath, mode = 'r+', encoding=\"ascii\", errors=\"surrogateescape\" )\n",
    "        # with open(filepath) as of\n",
    "        for line in of:\n",
    "        # Split into lines on the basis of . ? or !\n",
    "            for split in re.split(\"\\.|\\?|\\!\", line):\n",
    "                # Was thinking of only keeping the alphabets here, but then it removes . also\n",
    "                # Here's a solution\n",
    "                splitb = \"\".join([c for c in split if c in string.ascii_letters or c in string.whitespace])\n",
    "                # Debug: print(splitb)\n",
    "                # f.write(\"\\t\")\n",
    "                splitc = splitb.strip()\n",
    "                if splitc.startswith('X'):\n",
    "                    continue\n",
    "                if len(splitc.split()) < 8: \n",
    "                    continue\n",
    "                splitd = splitc + '\\n'\n",
    "                f.write(splitd)\n",
    "                # f.write('\\n')\n",
    "                line_count += 1\n",
    "        of.close()\n",
    "f.close()\n",
    "print('Number of lines in the file: ', line_count)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Training data and labels for the intent network\n",
    "\n",
    "\n",
    "mode = 'TR'\n",
    "rel_dir = Directory(mode)\n",
    "# print(rel_dir.preprocessing_dir)\n",
    "print(rel_dir.data_path)\n",
    "\n",
    "# data directories for cnf \n",
    "tar_dir = rel_dir.data_path + '/tar'\n",
    "\n",
    "\n",
    "raw_data_filename = tar_dir + rel_dir.raw_data_filename\n",
    "data_filename = tar_dir + rel_dir.data_filename\n",
    "\n",
    "# The Gold label in this case is just the weak label expressed as a single value\n",
    "gold_label_filename = tar_dir + rel_dir.gold_label_filename\n",
    "\n",
    "# And this is the label we'll conver to the 2 class format later\n",
    "weak_label_filename = tar_dir + rel_dir.weak_label_filename\n",
    "\n",
    "# data = pd.read_csv(raw_data_filename, sep='\\t')\n",
    "f = open(raw_data_filename, encoding='ascii', mode='r')\n",
    "data1 = f.readlines()\n",
    "data = []\n",
    "\n",
    "# Remove short lines. Found that they are not very useful for action\n",
    "# If I was doing feature engineering, leanght could be one of the features for intent extraction\n",
    "for line in data1:\n",
    "    if len(line.split()) > 8: \n",
    "        data.append(line.lstrip())\n",
    "    \n",
    "print('Number of lines read from the tar raw file: ', len(data))\n",
    "wlabels = generate_weak_labels(data)\n",
    "f.close()\n",
    "\n",
    "# Cannot just copy the file. Got to break into train test and validation\n",
    "# copyfile(raw_data_filename, data_filename)\n",
    "         \n",
    "# First breaking into train and test\n",
    "         \n",
    "# Split into train and test\n",
    "xtr, xte, ytr, yte = train_test_split(\n",
    "        data,\n",
    "        wlabels,\n",
    "        test_size=.2,\n",
    "        random_state=0,\n",
    "        stratify=wlabels)\n",
    "         \n",
    "\n",
    "# Write train data\n",
    "\n",
    "with open(data_filename, 'w') as fp:\n",
    "    for item in xtr:\n",
    "        fp.write(item)\n",
    "        \n",
    "with open(weak_label_filename, 'w') as fpw:\n",
    "    for item in ytr:\n",
    "        fpw.write(item + '\\n')\n",
    "    \n",
    "# The gold labels in this case are same as the weak\n",
    "# We want them here to later use to calculate accuracy for the tar network\n",
    "with open(gold_label_filename, 'w') as fpw:\n",
    "    for item in ytr:\n",
    "        fpw.write(item + '\\n')\n",
    "            \n",
    "# Splitting test into test and validation\n",
    "xv, xte, yv, yte = train_test_split(\n",
    "        xte,\n",
    "        yte,\n",
    "        test_size=.5,\n",
    "        random_state=0,\n",
    "        stratify=yte)        \n",
    "         \n",
    "# Writing it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the ratio of requests in training data\n",
    "county = 0\n",
    "countt = 0\n",
    "for line in ytr:\n",
    "    if line.strip() == \"Yes\":\n",
    "        county += 1\n",
    "    countt += 1\n",
    "    \n",
    "print('Requests, total, ratio', county, countt, county/countt)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data for tar\n",
    "\n",
    "mode = 'TE'\n",
    "rel_dir = Directory(mode)\n",
    "# print(rel_dir.preprocessing_dir)\n",
    "print(rel_dir.data_path)\n",
    "\n",
    "# data directories for cnf \n",
    "tar_dir = rel_dir.data_path + '/tar'\n",
    "\n",
    "\n",
    "# Create the cnf training, test and validation files\n",
    "\n",
    "# Training\n",
    "\n",
    "data_filename = tar_dir + rel_dir.data_filename\n",
    "weak_label_filename = tar_dir + rel_dir.weak_label_filename\n",
    "gold_label_filename = tar_dir + rel_dir.gold_label_filename\n",
    "\n",
    "with open(data_filename, 'w') as fp:\n",
    "    for item in xte:\n",
    "        fp.write(item)\n",
    "    \n",
    "with open(weak_label_filename, 'w') as fpw:\n",
    "    for item in yte:\n",
    "        fpw.write(item + '\\n')\n",
    "        \n",
    "with open(gold_label_filename, 'w') as fpw:\n",
    "    for item in yte:\n",
    "        fpw.write(item + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data for tar\n",
    "\n",
    "\n",
    "mode = 'VA'\n",
    "rel_dir = Directory(mode)\n",
    "# print(rel_dir.preprocessing_dir)\n",
    "print(rel_dir.data_path)\n",
    "\n",
    "# data directories for cnf \n",
    "tar_dir = rel_dir.data_path + '/tar'\n",
    "\n",
    "\n",
    "# Create the cnf training, test and validation files\n",
    "\n",
    "# Training\n",
    "\n",
    "data_filename = tar_dir + rel_dir.data_filename\n",
    "weak_label_filename = tar_dir + rel_dir.weak_label_filename\n",
    "gold_label_filename = tar_dir + rel_dir.gold_label_filename\n",
    "\n",
    "with open(data_filename, 'w') as fp:\n",
    "    for item in xv:\n",
    "        fp.write(item)\n",
    "    \n",
    "with open(weak_label_filename, 'w') as fpw:\n",
    "    for item in yv:\n",
    "        fpw.write(item + '\\n')\n",
    "        \n",
    "with open(gold_label_filename, 'w') as fpw:\n",
    "    for item in yv:\n",
    "        fpw.write(item + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code\n",
    "fileename = tar_dir + rel_dir.data_filename\n",
    "dataa_file = open(fileename, 'r')\n",
    "count = 0\n",
    "for _ in dataa_file:\n",
    "    count += 1\n",
    "dataa_file.close()\n",
    "print('Found count: \\n', count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picking the dictionary from:  /Users/gkhanna/w266nlp/2018-summer-main/project/learn-by-weak-supervision-master/global_module/utility_dir/folder2/vocab/word_vocab.pkl\n"
     ]
    }
   ],
   "source": [
    "# Making the dictionary from all the training data\n",
    "from global_module.settings_module.set_dict import Dictionary\n",
    "word_dict = Dictionary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many words in the dictionary\n",
    "print(word_dict.word_dict.get(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test the dictionary\n",
    "print(word_dict.word_dict.get('please'))\n",
    "print(word_dict.word_dict.get('request'))\n",
    "print(word_dict.word_dict.get('thanks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from global_module.implementation_module import train\n",
    "train.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading during train_run : /Users/gkhanna/w266nlp/2018-summer-main/project/learn-by-weak-supervision-master/global_module/utility_dir/folder2/data/cnf/tokenized_test.txt\n",
      "Found count: \n",
      " 496\n",
      "Reading during train_run : /Users/gkhanna/w266nlp/2018-summer-main/project/learn-by-weak-supervision-master/global_module/utility_dir/folder2/data/tar/tokenized_test.txt\n",
      "Found count: \n",
      " 9269\n",
      "INITIALIZING TF GRAPH \n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "Extracted word embedding\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /Users/gkhanna/w266nlp/2018-summer-main/project/learn-by-weak-supervision-master/global_module/implementation_module/target_network.py:37: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "TF GRAPH INITIALIZED\n",
      "STARTING THE TEST EPOCHS: \n",
      " 1\n",
      "\n",
      " Starting CNF Epoch: \n",
      " 1\n",
      "Checkpoint during the Epoch: Loading model from: /Users/gkhanna/w266nlp/2018-summer-main/project/learn-by-weak-supervision-master/global_module/utility_dir/folder2/models/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from /Users/gkhanna/w266nlp/2018-summer-main/project/learn-by-weak-supervision-master/global_module/utility_dir/folder2/models/model.ckpt\n",
      "Epoch : 1, CE loss: 20.5556\n",
      "CNF NETWORK: Epoch: 1 Test loss: 20.556\n",
      "1 CNF epoch run takes 0.07307558059692383 minutes.\n",
      "\n",
      " Finished CNF epoch: \n",
      " 1\n",
      "\n",
      "Starting TGT epoch: \n",
      " 1\n",
      "Ratio of requests in tar_input 0.02244039270687237\n",
      "tar network accuracy: 0.9778\n",
      "Epoch Num: 1, tar loss: 309.9886\n",
      "TGT NETWORK: Epoch: 1 Test loss: 309.989\n",
      "\n",
      "1 TGT epoch run takes 1.2227224151293437 minutes.\n",
      "\n",
      "Finishing TGT epoch: \n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "from global_module.implementation_module.train import Train\n",
    "Train().run_test(word_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
